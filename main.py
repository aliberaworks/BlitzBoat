"""
BlitzBoat Main CLI â€” å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆ
Usage:
  python main.py --collect              # éå»6ãƒ¶æœˆãƒ‡ãƒ¼ã‚¿åé›† (ä¸­æ–­å†é–‹OK)
  python main.py --analyze 20260218     # æŒ‡å®šæ—¥ã®ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ†æ
  python main.py --daily                # æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œ
  python main.py --stats                # ä¼šå ´çµ±è¨ˆå†è¨ˆç®—
  python main.py --test                 # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ†ã‚¹ãƒˆ
"""
import argparse
import json
import os
import sys
from datetime import datetime, timedelta

import config
from scraper import (
    scrape_racelist,
    scrape_beforeinfo,
    scrape_race_result,
    scrape_today_venues,
    collect_historical_results,
    collect_daily_results,
    load_all_results,
    save_all_results,
)
from analyzer import identify_chance_races, is_boat1_weak, is_st_slow
from statistics_engine import (
    build_venue_stats,
    get_venue_ranking,
    save_venue_stats,
    load_venue_stats,
    print_venue_ranking,
)
from ticket_generator import generate_tickets, print_tickets
from line_bot import notify_chance_races, format_chance_race_message
from shorts_generator import generate_shorts_video
from x_poster import run_x_post, generate_summary_image
from note_drafter import run_note_draft


def cmd_collect(args):
    """éå»ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬åé›†"""
    days = args.days or config.COLLECTION_DAYS
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"  BlitzBoat â€” éå»{days}æ—¥é–“ãƒ‡ãƒ¼ã‚¿åé›†")
    print(f"  ä¸­æ–­ã—ã¦ã‚‚ `--collect` ã§å†é–‹å¯èƒ½")
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    stats = collect_historical_results(days)
    
    # çµ±è¨ˆã‚’å†è¨ˆç®—
    print("\nä¼šå ´çµ±è¨ˆã‚’å†è¨ˆç®—ä¸­...")
    results = load_all_results()
    venue_stats = build_venue_stats(results)
    save_venue_stats(venue_stats)
    print(f"å®Œäº†: {len(venue_stats)} ä¼šå ´ã®çµ±è¨ˆã‚’æ›´æ–°")


def cmd_analyze(args):
    """æŒ‡å®šæ—¥ã®ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ†æ"""
    target_date = args.date or datetime.now().strftime("%Y%m%d")
    
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"  BlitzBoat â€” {target_date} ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ†æ")
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # ä¼šå ´çµ±è¨ˆãƒ­ãƒ¼ãƒ‰
    venue_stats = load_venue_stats()
    if not venue_stats:
        print("âš  ä¼šå ´çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒæœªä½œæˆã§ã™ã€‚å…ˆã« --collect ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        print("  ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã¨ã—ã¦çµ±è¨ˆãªã—ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    
    # å½“æ—¥ã®é–‹å‚¬ä¼šå ´ã‚’å–å¾—
    venues = scrape_today_venues(target_date)
    if not venues:
        print(f"  {target_date} ã®é–‹å‚¬æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        print(f"  å…¨ä¼šå ´ã‚’è©¦è¡Œã—ã¾ã™...")
        venues = [{"jcd": jcd, "name": name} for jcd, name in config.VENUE_CODES.items()]
    
    print(f"\n  é–‹å‚¬ä¼šå ´: {', '.join(v['name'] for v in venues)}")
    
    # å…¨ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    all_races = []
    for venue in venues:
        jcd = venue["jcd"]
        venue_name = venue.get("name", "")
        print(f"\n  [{venue_name}] ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
        
        for rno in range(1, 13):
            entries = scrape_racelist(jcd, target_date, rno)
            if not entries:
                continue
            
            st_info = scrape_beforeinfo(jcd, target_date, rno)
            
            race_data = {
                "date": target_date,
                "venue": jcd,
                "venue_name": venue_name,
                "race_no": rno,
                "entries": entries,
                "st_info": st_info,
            }
            all_races.append(race_data)
    
    print(f"\n  å–å¾—ãƒ¬ãƒ¼ã‚¹æ•°: {len(all_races)}")
    
    # ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ¤å®š
    chance_races = identify_chance_races(all_races)
    
    if not chance_races:
        print("\n  âŒ ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹è©²å½“ãªã—")
        return
    
    print(f"\n  ğŸ”¥ ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹: {len(chance_races)} ä»¶æ¤œå‡º!")
    
    # å„ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹ã®è©³ç´°ã‚’è¡¨ç¤º
    for i, cr in enumerate(chance_races):
        boat1 = cr["boat1"]
        venue_name = cr["venue_name"]
        race_no = cr["race_no"]
        win_prob = cr["boat1_win_prob"]
        
        print(f"\n{'â•'*60}")
        print(f"  ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹ #{i+1}: {venue_name} {race_no}R")
        print(f"{'â•'*60}")
        print(f"  1å·è‰‡: {boat1['name']}")
        print(f"  å…¨å›½å‹ç‡: {boat1['national_rate']:.2f}")
        print(f"  å½“åœ°å‹ç‡: {boat1['local_rate']:.2f}")
        print(f"  1å·è‰‡å‹ç‡æ¨å®š: {win_prob*100:.1f}%")
        print(f"  {cr['cond1']['reason']}")
        print(f"  {cr['cond2']['reason']}")
        
        # å‡ºç›®ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        jcd = cr["venue"]
        if venue_stats and jcd in venue_stats:
            print_venue_ranking(venue_stats, jcd, top_n=20)
            
            # æ¨å¥¨èˆŸåˆ¸
            patterns = get_venue_ranking(venue_stats, jcd)
            if patterns:
                tickets = generate_tickets(patterns)
                print_tickets(tickets, venue_name, race_no)
    
    # çµæœã‚’JSONä¿å­˜
    output_file = os.path.join(config.DAILY_DIR, f"analysis_{target_date}.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "date": target_date,
            "total_races": len(all_races),
            "chance_races": chance_races,
        }, f, ensure_ascii=False, indent=2, default=str)
    print(f"\n  åˆ†æçµæœä¿å­˜: {output_file}")


def cmd_daily(args):
    """æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œ (GitHub Actionsç”¨)"""
    today = datetime.now()
    yesterday = (today - timedelta(days=1)).strftime("%Y%m%d")
    today_str = today.strftime("%Y%m%d")
    
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"  BlitzBoat â€” æ—¥æ¬¡æ›´æ–° {today_str}")
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # 1. å‰æ—¥çµæœã‚’åé›†
    print(f"\n[1/7] å‰æ—¥({yesterday})ã®çµæœã‚’åé›†...")
    daily_results = collect_daily_results(yesterday)
    if daily_results:
        all_results = load_all_results()
        for race in daily_results:
            key = f"{race['venue']}_{race['date']}"
            if key not in all_results:
                all_results[key] = []
            all_results[key].append(race)
        save_all_results(all_results)
        print(f"  {len(daily_results)} ãƒ¬ãƒ¼ã‚¹ã®çµæœã‚’è¿½åŠ ")
    
    # 2. çµ±è¨ˆå†è¨ˆç®—
    print(f"\n[2/7] ä¼šå ´çµ±è¨ˆã‚’å†è¨ˆç®—...")
    results = load_all_results()
    venue_stats = build_venue_stats(results)
    save_venue_stats(venue_stats)
    print(f"  {len(venue_stats)} ä¼šå ´ã®çµ±è¨ˆã‚’æ›´æ–°")
    
    # 3. æœ¬æ—¥ã®ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ†æ
    print(f"\n[3/7] æœ¬æ—¥({today_str})ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æ...")
    venues = scrape_today_venues(today_str)
    all_races = []
    for venue in venues:
        jcd = venue["jcd"]
        venue_name = venue.get("name", "")
        for rno in range(1, 13):
            entries = scrape_racelist(jcd, today_str, rno)
            if not entries:
                continue
            st_info = scrape_beforeinfo(jcd, today_str, rno)
            all_races.append({
                "date": today_str,
                "venue": jcd,
                "venue_name": venue_name,
                "race_no": rno,
                "entries": entries,
                "st_info": st_info,
            })
    
    chance_races = identify_chance_races(all_races)
    print(f"  ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹: {len(chance_races)} ä»¶")
    
    # 4. LINEé€šçŸ¥
    print(f"\n[4/7] LINEé€šçŸ¥...")
    notify_chance_races(chance_races, venue_stats)
    
    # 5. YouTube Shortsç”Ÿæˆ
    print(f"\n[5/7] YouTube Shortsç”Ÿæˆ...")
    if chance_races:
        top_race = chance_races[0]
        video_path = generate_shorts_video(top_race)
        print(f"  å‹•ç”»: {video_path}")
    else:
        print("  ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹ãªã—ã€‚å‹•ç”»ç”Ÿæˆã‚¹ã‚­ãƒƒãƒ—ã€‚")
    
    # 6. X (Twitter) è‡ªå‹•æŠ•ç¨¿
    print(f"\n[6/7] Xè‡ªå‹•æŠ•ç¨¿...")
    if chance_races:
        x_ok = run_x_post(chance_races, today_str)
        if x_ok:
            print("  XæŠ•ç¨¿å®Œäº†!")
    else:
        print("  ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹ãªã—ã€‚XæŠ•ç¨¿ã‚¹ã‚­ãƒƒãƒ—ã€‚")
    
    # 7. note.com ä¸‹æ›¸ãä¿å­˜
    print(f"\n[7/7] noteä¸‹æ›¸ãä¿å­˜...")
    if chance_races:
        venue_stats_summary = {
            jcd: {
                "name": data.get("name", ""),
                "total_races": data.get("total_races", 0),
                "top_patterns": data.get("patterns", [])[:5],
            }
            for jcd, data in venue_stats.items()
        }
        note_ok = run_note_draft(chance_races, venue_stats_summary, today_str)
        if note_ok:
            print("  noteä¸‹æ›¸ãä¿å­˜å®Œäº†! ç¢ºèªãƒ»å…¬é–‹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
    else:
        print("  ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹ãªã—ã€‚noteä¸‹æ›¸ãã‚¹ã‚­ãƒƒãƒ—ã€‚")
    
    # åˆ†æçµæœã‚’JSONä¿å­˜  (Vercelç”¨)
    output_file = os.path.join(config.DAILY_DIR, f"daily_{today_str}.json")
    daily_output = {
        "date": today_str,
        "updated_at": today.isoformat(),
        "total_races": len(all_races),
        "chance_races": chance_races,
        "venue_stats_summary": {
            jcd: {
                "name": data.get("name", ""),
                "total_races": data.get("total_races", 0),
                "filtered_races": data.get("filtered_races", 0),
                "top_patterns": data.get("patterns", [])[:10],
            }
            for jcd, data in venue_stats.items()
        },
    }
    
    # æ¨å¥¨èˆŸåˆ¸ã‚‚è¿½åŠ 
    for cr in daily_output["chance_races"]:
        jcd = cr.get("venue", "")
        patterns = get_venue_ranking(venue_stats, jcd)
        if patterns:
            cr["tickets"] = generate_tickets(patterns)
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(daily_output, f, ensure_ascii=False, indent=2, default=str)
    print(f"\n  æ—¥æ¬¡åˆ†æä¿å­˜: {output_file}")
    print(f"\nâœ… æ—¥æ¬¡æ›´æ–°å®Œäº†")


def cmd_stats(args):
    """ä¼šå ´çµ±è¨ˆã®å†è¨ˆç®—"""
    print("ä¼šå ´çµ±è¨ˆã‚’å†è¨ˆç®—ä¸­...")
    results = load_all_results()
    if not results:
        print("âš  ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã« --collect ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    
    venue_stats = build_venue_stats(results)
    save_venue_stats(venue_stats)
    
    for jcd in sorted(venue_stats.keys()):
        print_venue_ranking(venue_stats, jcd, top_n=10)


def cmd_test(args):
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å‹•ä½œãƒ†ã‚¹ãƒˆ"""
    jcd = args.venue or "01"
    hd = args.date or datetime.now().strftime("%Y%m%d")
    rno = args.race or 1
    venue_name = config.VENUE_CODES.get(jcd, jcd)
    
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"  ãƒ†ã‚¹ãƒˆ: {venue_name} {hd} {rno}R")
    print(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    print(f"\n[1] å‡ºèµ°è¡¨...")
    entries = scrape_racelist(jcd, hd, rno)
    for e in entries:
        print(f"  {e['boat']}å·è‰‡: {e['name']} å…¨å›½{e['national_rate']} å½“åœ°{e['local_rate']} ãƒ¢ãƒ¼ã‚¿ãƒ¼{e['motor_no']}")
    
    print(f"\n[2] ç›´å‰æƒ…å ±...")
    st_info = scrape_beforeinfo(jcd, hd, rno)
    for s in st_info:
        print(f"  {s['boat']}å·è‰‡: ST {s['exhibit_st']}")
    
    print(f"\n[3] ãƒ¬ãƒ¼ã‚¹çµæœ...")
    result = scrape_race_result(jcd, hd, rno)
    if result:
        print(f"  æ±ºã¾ã‚Šæ‰‹: {result.get('kimarite', 'N/A')}")
        print(f"  3é€£å˜: {result.get('trifecta', 'N/A')}")
        print(f"  ST: {result.get('start_times', [])}")


def main():
    parser = argparse.ArgumentParser(
        description="BlitzBoat â€” çµ±è¨ˆãƒ™ãƒ¼ã‚¹ç«¶è‰‡æˆ¦ç•¥ã‚·ã‚¹ãƒ†ãƒ ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    sub = parser.add_subparsers(dest="command")
    
    # --collect
    p_collect = sub.add_parser("collect", help="éå»ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬åé›†")
    p_collect.add_argument("--days", type=int, default=None, help="åé›†æ—¥æ•° (default: 180)")
    
    # --analyze
    p_analyze = sub.add_parser("analyze", help="ãƒãƒ£ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚¹åˆ†æ")
    p_analyze.add_argument("--date", type=str, default=None, help="å¯¾è±¡æ—¥ YYYYMMDD")
    
    # --daily
    p_daily = sub.add_parser("daily", help="æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œ")
    
    # --stats
    p_stats = sub.add_parser("stats", help="ä¼šå ´çµ±è¨ˆå†è¨ˆç®—")
    
    # --test
    p_test = sub.add_parser("test", help="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ†ã‚¹ãƒˆ")
    p_test.add_argument("--venue", type=str, default="01", help="ä¼šå ´ã‚³ãƒ¼ãƒ‰")
    p_test.add_argument("--date", type=str, default=None, help="æ—¥ä»˜ YYYYMMDD")
    p_test.add_argument("--race", type=int, default=1, help="ãƒ¬ãƒ¼ã‚¹ç•ªå·")
    
    args = parser.parse_args()
    
    if args.command == "collect":
        cmd_collect(args)
    elif args.command == "analyze":
        cmd_analyze(args)
    elif args.command == "daily":
        cmd_daily(args)
    elif args.command == "stats":
        cmd_stats(args)
    elif args.command == "test":
        cmd_test(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
